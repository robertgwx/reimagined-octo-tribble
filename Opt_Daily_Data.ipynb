{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "14m2TRJ1prp-nbfq1tPu_bo-h_5f06JVq",
      "authorship_tag": "ABX9TyNn07t5PlEHXINbbRrYYw48",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robertgwx/reimagined-octo-tribble/blob/main/Opt_Daily_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjG6Ct8iDfkf"
      },
      "source": [
        "## Defining the function to fetch all daily data using only stations incl. in LTCE threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqCDZ_mmhrst"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from io import StringIO\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import calendar\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "from tabulate import tabulate\n",
        "from scipy import stats\n",
        "import glob\n",
        "from heapq import nlargest\n",
        "import contextlib # Keep import as other functions might use it\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "## DEFINE ALL FUNCTIONS\n",
        "# Function to convert title case, but avoid capitalizing letters after apostrophes.\n",
        "def custom_title_case(text):\n",
        "    return re.sub(r\"(\\s|^)([a-z])|(')([a-z])\",\n",
        "                  lambda m: (m.group(1) or \"\") + (m.group(2).upper() if m.group(2) else \"\")\n",
        "                  if m.group(1) or m.group(2) else (m.group(3) or \"\") + (m.group(4) if m.group(4) else \"\"),\n",
        "                  text)\n",
        "\n",
        "# Assuming base_url is defined globally or passed to functions that need it\n",
        "base_url = \"https://climate.weather.gc.ca/climate_data/bulk_data_e.html\"\n",
        "\n",
        "\n",
        "def fetch_daily_data(station_id, station_name, year, current_month):\n",
        "    all_daily_data = []\n",
        "    current_date = datetime.now()\n",
        "\n",
        "    # Fetch data for all months in the year\n",
        "    for month in range(1, 13): # Fetch all 12 months\n",
        "        # Skip months after the current month if it's the current year\n",
        "        if year == current_date.year and month > current_date.month:\n",
        "            break\n",
        "        params = {\n",
        "            \"format\": \"csv\",\n",
        "            \"stationID\": station_id,\n",
        "            \"Year\": year,\n",
        "            \"Month\": month,\n",
        "            \"timeframe\": 2,  # Daily data\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.get(base_url, params=params)\n",
        "\n",
        "            if response.status_code == 200 and response.content.strip():\n",
        "                csv_data = StringIO(response.content.decode(\"utf-8\"))\n",
        "                data = pd.read_csv(csv_data)\n",
        "\n",
        "                if not data.empty:\n",
        "                    # Define desired columns\n",
        "                    desired_columns = [\n",
        "                        \"Date/Time\",\n",
        "                        \"Max Temp (°C)\",\n",
        "                        \"Min Temp (°C)\",\n",
        "                        \"Mean Temp (°C)\",\n",
        "                        \"Total Rain (mm)\",\n",
        "                        \"Total Snow (cm)\",\n",
        "                        \"Total Precip (mm)\",\n",
        "                        \"Snow on Grnd (cm)\",\n",
        "                        \"Spd of Max Gust (km/h)\"\n",
        "                    ]\n",
        "\n",
        "                    # Filter columns that actually exist in the dataframe\n",
        "                    existing_columns = [col for col in desired_columns if col in data.columns]\n",
        "\n",
        "                    # Select only existing columns\n",
        "                    data = data[existing_columns]\n",
        "\n",
        "                    # Filter data for specific month and year\n",
        "                    data_month = data[\n",
        "                        (pd.to_datetime(data['Date/Time']).dt.month == month) &\n",
        "                        (pd.to_datetime(data['Date/Time']).dt.year == year)\n",
        "                    ].copy()\n",
        "\n",
        "                    # Format 'Date/Time' to only include date (YYYY-MM-DD)\n",
        "                    data_month['Date/Time'] = pd.to_datetime(data_month['Date/Time']).dt.strftime('%Y-%m-%d')\n",
        "\n",
        "                    # Add station info to daily data\n",
        "                    data_month['Station Name'] = station_name\n",
        "                    data_month['Station ID'] = station_id\n",
        "                    all_daily_data.extend(data_month.to_dict('records'))\n",
        "\n",
        "        except Exception as e:\n",
        "            # Keep original print for now or modify to accept stream if needed elsewhere\n",
        "            print(f\"Error fetching data for {station_name} in {year}, month {month}: {e}\")\n",
        "\n",
        "\n",
        "    return all_daily_data\n",
        "\n",
        "def fetch_daily_data_range(station_id, station_name, start_date, end_date, output_stream=sys.stdout):\n",
        "    \"\"\"\n",
        "    Fetch daily weather data for a specific station within a given date range.\n",
        "\n",
        "    Args:\n",
        "        station_id (str): Unique identifier for the weather station\n",
        "        station_name (str): Name of the weather station\n",
        "        start_date (datetime): Starting date for data retrieval\n",
        "        end_date (datetime): Ending date for data retrieval\n",
        "        output_stream: Stream to write output messages (e.g., sys.stdout or widget output)\n",
        "\n",
        "    Returns:\n",
        "        list: Daily weather records within the specified date range\n",
        "    \"\"\"\n",
        "    # Validate date range\n",
        "    if start_date > end_date:\n",
        "        print(\"Error: Start date must be before or equal to end date\", file=output_stream)\n",
        "        return []\n",
        "\n",
        "    # Calculate years involved in the date range\n",
        "    years_involved = sorted(list(set(range(start_date.year, end_date.year + 1))))\n",
        "\n",
        "    daily_records = []\n",
        "\n",
        "    for year in years_involved:\n",
        "        # Determine start and end months for the current year\n",
        "        start_month = start_date.month if year == start_date.year else 1\n",
        "        end_month = end_date.month if year == end_date.year else 12\n",
        "\n",
        "        for month in range(start_month, end_month + 1):\n",
        "            # If it's the end year and the current month is after the end_date's month, stop.\n",
        "            if year == end_date.year and month > end_date.month:\n",
        "                break\n",
        "\n",
        "            # Fetch daily data for the specific month and year\n",
        "            params = {\n",
        "                \"format\": \"csv\",\n",
        "                \"stationID\": station_id,\n",
        "                \"Year\": year,\n",
        "                \"Month\": month,\n",
        "                \"timeframe\": 2,  # Daily data\n",
        "            }\n",
        "\n",
        "            try:\n",
        "                response = requests.get(base_url, params=params)\n",
        "\n",
        "                if response.status_code == 200 and response.content.strip():\n",
        "                    csv_data = StringIO(response.content.decode(\"utf-8\"))\n",
        "                    data = pd.read_csv(csv_data)\n",
        "\n",
        "                    if not data.empty:\n",
        "                        # Define desired columns\n",
        "                        desired_columns = [\n",
        "                            \"Date/Time\",\n",
        "                            \"Max Temp (°C)\",\n",
        "                            \"Min Temp (°C)\",\n",
        "                            \"Mean Temp (°C)\",\n",
        "                            \"Total Rain (mm)\",\n",
        "                            \"Total Snow (cm)\",\n",
        "                            \"Total Precip (mm)\",\n",
        "                            \"Snow on Grnd (cm)\",\n",
        "                            \"Spd of Max Gust (km/h)\"\n",
        "                        ]\n",
        "\n",
        "                        # Filter columns that actually exist in the dataframe\n",
        "                        existing_columns = [col for col in desired_columns if col in data.columns]\n",
        "\n",
        "                        # Select only existing columns\n",
        "                        data = data[existing_columns]\n",
        "\n",
        "                        # Filter data for the specific date range within this month\n",
        "                        data['Date/Time'] = pd.to_datetime(data['Date/Time'])\n",
        "                        data_range_month = data[\n",
        "                            (data['Date/Time'].dt.date >= start_date.date()) &\n",
        "                            (data['Date/Time'].dt.date <= end_date.date())\n",
        "                        ].copy()\n",
        "\n",
        "\n",
        "                        if not data_range_month.empty:\n",
        "                            # Format 'Date/Time' to only include date (YYYY-MM-DD)\n",
        "                            data_range_month['Date/Time'] = data_range_month['Date/Time'].dt.strftime('%Y-%m-%d')\n",
        "\n",
        "                            # Add station info to daily data\n",
        "                            data_range_month['Station Name'] = station_name\n",
        "                            data_range_month['Station ID'] = station_id\n",
        "                            daily_records.extend(data_range_month.to_dict('records'))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error fetching data for {station_name} in {year}, month {month}: {e}\", file=output_stream)\n",
        "\n",
        "    return daily_records\n",
        "\n",
        "\n",
        "def get_locations_from_csv(folder_path):\n",
        "    \"\"\"Gets a list of unique locations from CSV filenames in a folder.\n",
        "\n",
        "    Args:\n",
        "        folder_path: The path to the folder containing the CSV files.\n",
        "\n",
        "    Returns:\n",
        "        A list of unique location names.\n",
        "    \"\"\"\n",
        "    locations = set()  # Use a set to avoid duplicates\n",
        "    if not os.path.exists(folder_path):\n",
        "        return []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".csv\"):\n",
        "            # Extract location name using regular expression\n",
        "            match = re.search(r\"(.+)_daily_data\\.csv\", filename)\n",
        "            if match:\n",
        "                location_name = match.group(1)\n",
        "                locations.add(location_name)\n",
        "    return list(locations)\n",
        "\n",
        "def remove_duplicate_dates(filepath, output_stream=sys.stdout):\n",
        "    \"\"\"\n",
        "    Removes duplicate dates from a single CSV file, keeping the row with more data.\n",
        "    \"\"\"\n",
        "    columns_to_check = ['Max Temp (°C)', 'Min Temp (°C)', 'Mean Temp (°C)', 'Total Precip (mm)',\n",
        "                        'Total Rain (mm)', 'Total Snow (cm)', 'Snow on Grnd (cm)', 'Spd of Max Gust (km/h)']\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "        df['Date/Time'] = pd.to_datetime(df['Date/Time'])\n",
        "        df = df.sort_values(by=['Date/Time'])\n",
        "\n",
        "        # Group by date and select the best row in each group\n",
        "        # Using .agg to specify columns to check for max non-null count\n",
        "        agg_dict = {col: 'first' for col in df.columns}\n",
        "        # Use a lambda that finds the index of the row with the most non-null values for the specified columns\n",
        "        for col in columns_to_check:\n",
        "            if col in df.columns:\n",
        "                 agg_dict[col] = lambda x: x.loc[x.notnull().sum().idxmax()] if x.notnull().sum() > 0 else np.nan\n",
        "\n",
        "\n",
        "        # Ensure all columns are included, using first for those not in columns_to_check\n",
        "        for col in df.columns:\n",
        "            if col not in agg_dict:\n",
        "                agg_dict[col] = 'first'\n",
        "\n",
        "        # Apply aggregation and reset index\n",
        "        df = df.groupby('Date/Time').agg(agg_dict).reset_index()\n",
        "\n",
        "\n",
        "        df.to_csv(filepath, index=False)\n",
        "        print(f\"Duplicate data removal complete for {os.path.basename(filepath)}.\", file=output_stream)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {filepath}: {e}\", file=output_stream)\n",
        "\n",
        "# New function to update a single CSV file with the most recent data\n",
        "def update_csv_file(file_path):\n",
        "    \"\"\"\n",
        "    Updates a single CSV file with the most recent data.\n",
        "    Prints status messages to standard output (will be captured by Output widget).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"\\nUpdating file: {file_path}\")\n",
        "\n",
        "        # Read existing data\n",
        "        existing_df = pd.read_csv(file_path)\n",
        "\n",
        "        if existing_df.empty:\n",
        "            print(f\"File {file_path} is empty. Skipping.\")\n",
        "            return\n",
        "\n",
        "        # Get the most recent Station ID and name from existing data\n",
        "        # Use .iloc[0] in case the dataframe is sorted descending by date\n",
        "        most_recent_record = existing_df.sort_values(by='Date/Time', ascending=False).iloc[0]\n",
        "        most_recent_station_id = most_recent_record['Station ID']\n",
        "        station_name = most_recent_record['Station Name']\n",
        "\n",
        "\n",
        "        # Get the most recent date from the CSV\n",
        "        most_recent_date_str = most_recent_record['Date/Time']\n",
        "        most_recent_date = pd.to_datetime(most_recent_date_str)\n",
        "\n",
        "\n",
        "        # Get current date\n",
        "        current_date = datetime.now()\n",
        "\n",
        "        print(f\"  Most recent data is from: {most_recent_date.strftime('%Y-%m-%d')}\")\n",
        "        print(f\"  Current date: {current_date.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "        # Determine the date from which to start fetching new data\n",
        "        # Start fetching from the day after the most recent date\n",
        "        start_fetch_date = most_recent_date + pd.Timedelta(days=1)\n",
        "\n",
        "        # If the start fetch date is today or in the future, no new data is needed\n",
        "        if start_fetch_date.date() >= current_date.date():\n",
        "            print(f\"  Data is already up to date (last record from {most_recent_date.strftime('%Y-%m-%d')}). No update needed.\")\n",
        "            return\n",
        "\n",
        "        print(f\"  Fetching new data from {start_fetch_date.strftime('%Y-%m-%d')} to {current_date.strftime('%Y-%m-%d')}...\")\n",
        "\n",
        "        # Fetch new data for the required date range, passing the output stream\n",
        "        all_new_records = fetch_daily_data_range(most_recent_station_id, station_name, start_fetch_date, current_date)\n",
        "\n",
        "\n",
        "        if all_new_records:\n",
        "            # Convert new records to DataFrame\n",
        "            new_df = pd.DataFrame(all_new_records)\n",
        "\n",
        "            # Define columns to check for non-null values\n",
        "            columns_to_check = ['Max Temp (°C)', 'Min Temp (°C)', 'Mean Temp (°C)', 'Total Precip (mm)',\n",
        "                                'Total Rain (mm)', 'Total Snow (cm)', 'Snow on Grnd (cm)', 'Spd of Max Gust (km/h)']\n",
        "\n",
        "            # Remove rows where ALL specified columns are empty/NaN in the new data\n",
        "            new_df = new_df.dropna(subset=columns_to_check, how='all')\n",
        "\n",
        "            if not new_df.empty:\n",
        "                # Ensure 'Date/Time' is datetime for comparison\n",
        "                existing_df['Date/Time'] = pd.to_datetime(existing_df['Date/Time'])\n",
        "                new_df['Date/Time'] = pd.to_datetime(new_df['Date/Time'])\n",
        "\n",
        "                # Filter out dates from new_df that are already in existing_df\n",
        "                new_df_filtered = new_df[~new_df['Date/Time'].isin(existing_df['Date/Time'])].copy()\n",
        "\n",
        "                if not new_df_filtered.empty:\n",
        "                    # Format 'Date/Time' back to string for saving\n",
        "                    new_df_filtered['Date/Time'] = new_df_filtered['Date/Time'].dt.strftime('%Y-%m-%d')\n",
        "                    existing_df['Date/Time'] = existing_df['Date/Time'].dt.strftime('%Y-%m-%d')\n",
        "\n",
        "                    # Combine existing data with new data\n",
        "                    df_comprehensive_data = pd.concat([existing_df, new_df_filtered], ignore_index=True)\n",
        "\n",
        "                    # Save the data to the CSV file\n",
        "                    df_comprehensive_data.to_csv(file_path, mode=\"w\", index=False)\n",
        "\n",
        "                    print(f\"  Updated with {len(new_df_filtered)} new records.\")\n",
        "\n",
        "                else:\n",
        "                    print(f\"  No new data found after filtering existing dates.\")\n",
        "            else:\n",
        "                 print(f\"  No new data found with valid weather data.\")\n",
        "        else:\n",
        "            print(f\"  No new data fetched from the source.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  Error updating {file_path}: {str(e)}\")\n",
        "\n",
        "# Main script logic (This is likely not used by the widget directly, but keeping it for completeness)\n",
        "def main():\n",
        "    # Ask the user what they want to do\n",
        "    print(\"\\nClimate Data Update Options:\")\n",
        "    print(\"1. Update a specific location's data\")\n",
        "    print(\"2. Update all CSV files with the most recent data\")\n",
        "\n",
        "    choice = input(\"\\nEnter your choice (1 or 2): \").strip()\n",
        "\n",
        "    if choice == \"1\":\n",
        "        # Original code for updating a specific location\n",
        "        # Get the province abbreviation from the user\n",
        "        while True:\n",
        "            province = input(\"Enter the province abbreviation (e.g., NL, NS): \").upper()\n",
        "            if province in valid_provinces:\n",
        "                break  # Exit the loop if the input is valid\n",
        "            else:\n",
        "                print(\"Invalid province abbreviation. Please enter a valid abbreviation.\")\n",
        "\n",
        "        # Get the location name from the user\n",
        "        location_name = input(\"Enter the location name to search for: \")\n",
        "        location_name = custom_title_case(location_name)\n",
        "\n",
        "        # Rest of your original code for specific location update\n",
        "        try:\n",
        "            # Load climate stations\n",
        "            climate_stations = pd.read_csv('/content/drive/MyDrive/Climate Data/Station Inventory EN.csv')\n",
        "\n",
        "            # Find matching station IDs\n",
        "            location_name_modified = location_name.replace(\".\", \"\")  # Remove periods from input\n",
        "            matching_stations = climate_stations[\n",
        "                matching_stations['Name'].str.replace(\".\", \"\", regex=False).str.lower().str.startswith(location_name_modified.lower(), na=False)\n",
        "            ]\n",
        "\n",
        "            if matching_stations.empty:\n",
        "                print(f\"No stations found matching the location name: {location_name}\")\n",
        "                return\n",
        "\n",
        "            station_info = {}\n",
        "            for index, row in matching_stations.iterrows():\n",
        "                station_id = row['Station ID']\n",
        "                station_name = custom_title_case(location_name)\n",
        "                first_year = row['First Year']\n",
        "                last_year = row['Last Year']\n",
        "                station_info[station_id] = {'name': station_name, 'years': range(first_year, last_year + 1)}\n",
        "\n",
        "            # Get current year and month\n",
        "            current_year = datetime.now().year\n",
        "            current_month = datetime.now().month\n",
        "\n",
        "            # Create the output filename for daily data\n",
        "            output_file_daily = f\"/content/drive/MyDrive/Climate Data/Daily Data/{province}/{station_name}_daily_data.csv\"\n",
        "\n",
        "            # Check if the file exists\n",
        "            all_daily_records = []\n",
        "\n",
        "            if os.path.exists(output_file_daily):\n",
        "                # Update existing file with new data for current month\n",
        "                update_csv_file(output_file_daily)\n",
        "            else:\n",
        "                # If file doesn't exist, collect data for all years\n",
        "                for station_id, info in station_info.items():\n",
        "                    station_name = info['name']\n",
        "                    years = list(info['years'])  # Convert to list to get total years\n",
        "                    print(f\"\\nFetching data for station: {station_name} ({station_id})\")\n",
        "                    print(f\"Total years to fetch: {len(years)}\")\n",
        "\n",
        "                    # Fetch data for all years\n",
        "                    for year_index, year in enumerate(years, 1):\n",
        "                        print(f\"  Fetching data for Year {year} ({year_index}/{len(years)}) ...\")\n",
        "                        daily_records = fetch_daily_data(station_id, station_name, year, current_month)\n",
        "                        all_daily_records.extend(daily_records)\n",
        "\n",
        "                # Create DataFrame for daily records\n",
        "                df_comprehensive_data = pd.DataFrame(all_daily_records)\n",
        "\n",
        "                # Remove rows where ALL specified columns are empty/NaN\n",
        "                df_comprehensive_data = df_comprehensive_data.dropna(subset=columns_to_check, how='all')\n",
        "\n",
        "                # Create directory if it doesn't exist\n",
        "                os.makedirs(os.path.dirname(output_file_daily), exist_ok=True)\n",
        "\n",
        "                # Save the data to a CSV file\n",
        "                df_comprehensive_data.to_csv(output_file_daily, mode=\"w\", index=False)\n",
        "\n",
        "                print(f\"\\nFull data collection completed. Saved to {output_file_daily}\")\n",
        "\n",
        "                # Remove duplicate dates\n",
        "                remove_duplicate_dates(output_file_daily)\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(\"Error: Station Inventory EN.csv not found. Please upload the file.\")\n",
        "\n",
        "    elif choice == \"2\":\n",
        "        # New code for updating all CSV files\n",
        "        base_dir = \"/content/drive/MyDrive/Climate Data/Daily Data\"\n",
        "\n",
        "        if not os.path.exists(base_dir):\n",
        "            print(f\"Error: Directory {base_dir} not found.\")\n",
        "            return\n",
        "\n",
        "        # Find all CSV files in all province subdirectories\n",
        "        all_csv_files = []\n",
        "\n",
        "        for province in valid_provinces:\n",
        "            province_dir = os.path.join(base_dir, province)\n",
        "            if os.path.exists(province_dir):\n",
        "                csv_pattern = os.path.join(province_dir, \"*.csv\")\n",
        "                province_csv_files = glob.glob(csv_pattern)\n",
        "                all_csv_files.extend(province_csv_files)\n",
        "\n",
        "        if not all_csv_files:\n",
        "            print(\"No CSV files found in any province directories.\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\nFound {len(all_csv_files)} CSV files to update.\")\n",
        "\n",
        "        # Ask for confirmation\n",
        "        confirm = input(f\"Do you want to update all {len(all_csv_files)} files? (y/n): \").strip().lower()\n",
        "\n",
        "        if confirm == 'y':\n",
        "            # Update each CSV file\n",
        "            for i, file_path in enumerate(all_csv_files, 1):\n",
        "                print(f\"\\nUpdating file {i}/{len(all_csv_files)}: {os.path.basename(file_path)}\")\n",
        "                update_csv_file(file_path)\n",
        "\n",
        "            print(\"\\nAll files have been updated with the most recent data.\")\n",
        "        else:\n",
        "            print(\"Update cancelled.\")\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid choice. Please run the script again and select option 1 or 2.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2RuVW43p8Mb"
      },
      "source": [
        "# Defining the lookup function for data searches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBQlKZKlp753"
      },
      "outputs": [],
      "source": [
        "def get_meteorological_season(month):\n",
        "    \"\"\"Helper function to determine meteorological season from month\"\"\"\n",
        "    if month in [12, 1, 2]:\n",
        "        return 'Winter'\n",
        "    elif month in [3, 4, 5]:\n",
        "        return 'Spring'\n",
        "    else:  # 6, 7, 8, 9, 10, 11\n",
        "        return 'Summer' if month in [6, 7, 8] else 'Fall'\n",
        "\n",
        "def lookup_data(df, column, lookup_type, value=None, location=None, year=None, month=None):\n",
        "    \"\"\"\n",
        "    Perform flexible data lookups in a weather dataset\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pandas.DataFrame\n",
        "        The comprehensive weather dataset\n",
        "    column : str\n",
        "        The column to search (e.g., 'Max Temp (°C)', 'Total Precip (mm)')\n",
        "    lookup_type : str\n",
        "        Type of lookup to perform. Options:\n",
        "        - 'last_occurrence': Find the last time a specific value occurred\n",
        "        - 'first_occurrence': Find the first time a specific value occurred\n",
        "        - 'last_greater_than_or_equal': Last occurrence where value is >= specified value\n",
        "        - 'last_less_than_or_equal': Last occurrence where value is <= specified value\n",
        "        - 'count_greater_than_or_equal': Count of occurrences where value is >= specified value\n",
        "        - 'count_less_than_or_equal': Count of occurrences where value is <= specified value\n",
        "        - 'max_in_year': Maximum value for a given year\n",
        "        - 'min_in_year': Minimum value for a given year\n",
        "        - 'max_in_month': Maximum value for a given month\n",
        "        - 'min_in_month': Minimum value for a given month\n",
        "        - 'overall_max': Maximum value in entire dataset\n",
        "        - 'overall_min': Minimum value in entire dataset\n",
        "        - 'all_occurrences': Find all occurrences of a specific value\n",
        "        - 'all_greater_than_or_equal': Find all occurrences where value is >= specified value\n",
        "        - 'all_less_than_or_equal': Find all occurrences where value is <= specified value\n",
        "\n",
        "\n",
        "    value : float, optional\n",
        "        The specific value to look for (used with several lookup types)\n",
        "    location : str, optional\n",
        "        The specific location/station name to filter by\n",
        "    year : int, optional\n",
        "        The year to filter by\n",
        "    month : int, optional\n",
        "        The month to filter by\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    result : pandas.DataFrame or float or int\n",
        "        Depending on the lookup type, returns various types of results. For lookup types that return multiple occurrences, a DataFrame is returned.\n",
        "    \"\"\"\n",
        "    # Validate column exists\n",
        "    if column not in df.columns:\n",
        "        raise ValueError(f\"Column '{column}' not found in the dataset\")\n",
        "\n",
        "    # Create a copy of the dataframe to avoid modifying the original\n",
        "    data = df.copy()\n",
        "\n",
        "    # Apply location filtering if specified\n",
        "    if location is not None:\n",
        "        # Use case-insensitive matching for location\n",
        "        data = data[data['Station Name'].str.lower() == location.lower()]\n",
        "\n",
        "        if data.empty:\n",
        "            # Return empty DataFrame for consistency if no data for location\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    # Convert the column to numeric, coercing errors to NaN\n",
        "    data[column] = pd.to_numeric(data[column], errors='coerce')\n",
        "\n",
        "    # Apply filtering based on year and month if provided\n",
        "    if year is not None:\n",
        "        data = data[data['Year'] == year]\n",
        "\n",
        "    if month is not None:\n",
        "        data = data[data['Month'] == month]\n",
        "\n",
        "\n",
        "    # --- Lookup Types Returning DataFrames (Multiple Occurrences) ---\n",
        "    if lookup_type in ['last_occurrence', 'first_occurrence',\n",
        "                       'last_greater_than_or_equal', 'last_less_than_or_equal',\n",
        "                       'all_occurrences', 'all_greater_than_or_equal', 'all_less_than_or_equal']:\n",
        "        if value is None and lookup_type in ['last_occurrence', 'first_occurrence',\n",
        "                                             'last_greater_than_or_equal', 'last_less_than_or_equal',\n",
        "                                             'all_occurrences', 'all_greater_than_or_equal', 'all_less_than_or_equal']:\n",
        "             raise ValueError(\"'value' must be specified for this lookup type\")\n",
        "\n",
        "        if lookup_type in ['last_occurrence', 'first_occurrence', 'all_occurrences']:\n",
        "             matches = data[data[column] == value].copy()\n",
        "        elif lookup_type in ['last_greater_than_or_equal', 'all_greater_than_or_equal']:\n",
        "             matches = data[data[column] >= value].copy()\n",
        "        elif lookup_type in ['last_less_than_or_equal', 'all_less_than_or_equal']:\n",
        "             matches = data[data[column] <= value].copy()\n",
        "\n",
        "        if matches.empty:\n",
        "            return pd.DataFrame() # Return empty DataFrame if no matches\n",
        "\n",
        "        # Sort by date/time for consistent ordering\n",
        "        matches = matches.sort_values(by='Date/Time')\n",
        "\n",
        "        # For 'last' lookups, filter to only the last occurrence\n",
        "        if lookup_type in ['last_occurrence', 'last_greater_than_or_equal', 'last_less_than_or_equal']:\n",
        "             return matches.tail(1) # Return DataFrame with the last row\n",
        "        elif lookup_type in ['first_occurrence']:\n",
        "             return matches.head(1) # Return DataFrame with the first row\n",
        "        else: # 'all_occurrences', 'all_greater_than_or_equal', 'all_less_than_or_equal'\n",
        "             return matches # Return DataFrame with all matches\n",
        "\n",
        "\n",
        "    # --- Lookup Types Returning Single Values or Counts ---\n",
        "    elif lookup_type == 'count_greater_than_or_equal':\n",
        "        if value is None:\n",
        "            raise ValueError(\"'value' must be specified for count_greater_than_or_equal lookup\")\n",
        "        # Count occurrences where value is greater than or equal to specified value\n",
        "        count = (data[column] >= value).sum()\n",
        "        return count\n",
        "\n",
        "    elif lookup_type == 'count_less_than_or_equal':\n",
        "        if value is None:\n",
        "            raise ValueError(\"'value' must be specified for count_less_than_or_equal lookup\")\n",
        "        # Count occurrences where value is less than or equal to specified value\n",
        "        count = (data[column] <= value).sum()\n",
        "        return count\n",
        "\n",
        "    elif lookup_type in ['max_in_year', 'min_in_year', 'max_in_month', 'min_in_month', 'overall_max', 'overall_min']:\n",
        "        # Convert the column to numeric, coercing errors to NaN\n",
        "        data[column] = pd.to_numeric(data[column], errors='coerce')\n",
        "\n",
        "        if lookup_type == 'max_in_year':\n",
        "            if year is None:\n",
        "                raise ValueError(\"'year' must be specified for max_in_year lookup\")\n",
        "            max_value = data[column].max()\n",
        "            if pd.isna(max_value): return None, None # Handle case with no data\n",
        "            # Return DataFrame with all rows matching the max value\n",
        "            max_rows = data[data[column] == max_value].copy()\n",
        "            return max_rows # Return DataFrame\n",
        "\n",
        "        elif lookup_type == 'min_in_year':\n",
        "            if year is None:\n",
        "                raise ValueError(\"'year' must be specified for min_in_year lookup\")\n",
        "            min_value = data[column].min()\n",
        "            if pd.isna(min_value): return None, None # Handle case with no data\n",
        "            # Return DataFrame with all rows matching the min value\n",
        "            min_rows = data[data[column] == min_value].copy()\n",
        "            return min_rows # Return DataFrame\n",
        "\n",
        "        elif lookup_type == 'max_in_month':\n",
        "            if month is None:\n",
        "                raise ValueError(\"'month' must be specified for max_in_month lookup\")\n",
        "            max_value = data[column].max()\n",
        "            if pd.isna(max_value): return None, None # Handle case with no data\n",
        "            # Return DataFrame with all rows matching the max value\n",
        "            max_rows = data[data[column] == max_value].copy()\n",
        "            return max_rows # Return DataFrame\n",
        "\n",
        "        elif lookup_type == 'min_in_month':\n",
        "            if month is None:\n",
        "                raise ValueError(\"'month' must be specified for min_in_month lookup\")\n",
        "            min_value = data[column].min()\n",
        "            if pd.isna(min_value): return None, None # Handle case with no data\n",
        "            # Return DataFrame with all rows matching the min value\n",
        "            min_rows = data[data[column] == min_value].copy()\n",
        "            return min_rows # Return DataFrame\n",
        "\n",
        "\n",
        "        elif lookup_type == 'overall_max':\n",
        "            # Remove any filtering by year or month for overall lookups\n",
        "            data_overall = df.copy()\n",
        "            if location is not None:\n",
        "                data_overall = data_overall[data_overall['Station Name'].str.lower() == location.lower()]\n",
        "            # Convert the column to numeric, coercing errors to NaN\n",
        "            data_overall[column] = pd.to_numeric(data_overall[column], errors='coerce')\n",
        "            max_value = data_overall[column].max()\n",
        "            if pd.isna(max_value): return pd.DataFrame() # Handle case with no data\n",
        "            # Return DataFrame with all rows matching the overall max value\n",
        "            max_rows = data_overall[data_overall[column] == max_value].copy()\n",
        "            return max_rows # Return DataFrame\n",
        "\n",
        "        elif lookup_type == 'overall_min':\n",
        "            # Remove any filtering by year or month for overall lookups\n",
        "            data_overall = df.copy()\n",
        "            if location is not None:\n",
        "                data_overall = data_overall[data_overall['Station Name'].str.lower() == location.lower()]\n",
        "            # Convert the column to numeric, coercing errors to NaN\n",
        "            data_overall[column] = pd.to_numeric(data_overall[column], errors='coerce')\n",
        "            min_value = data_overall[column].min()\n",
        "            if pd.isna(min_value): return pd.DataFrame() # Handle case with no data\n",
        "            # Return DataFrame with all rows matching the overall min value\n",
        "            min_rows = data_overall[data_overall[column] == min_value].copy()\n",
        "            return min_rows # Return DataFrame\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid lookup_type: {lookup_type}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Widget Code"
      ],
      "metadata": {
        "id": "RmzkhtRoJTbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "from heapq import nlargest\n",
        "import calendar\n",
        "import os\n",
        "\n",
        "class InteractiveWeatherAnalyzer:\n",
        "    def __init__(self, base_folder_path):\n",
        "        self.base_folder_path = base_folder_path\n",
        "        self.valid_provinces = [\"NB\", \"NL\", \"NS\", \"PEI\", \"QC\"]\n",
        "        self.df = None\n",
        "        self.locations = []\n",
        "        self.current_province = None\n",
        "        self.analysis_results = [] # Store structured results (list of dicts)\n",
        "        self.current_result_index = 0 # Track current position in results\n",
        "\n",
        "        # Create all widgets\n",
        "        self.setup_widgets()\n",
        "        self.setup_layout()\n",
        "\n",
        "    def setup_widgets(self):\n",
        "        # === SELECTION WIDGETS ===\n",
        "        self.province_selector = widgets.Dropdown(\n",
        "            options=self.valid_provinces,\n",
        "            value='NL',\n",
        "            description='Province:',\n",
        "            style={'description_width': '80px'},\n",
        "            layout=widgets.Layout(width='200px')\n",
        "        )\n",
        "\n",
        "        self.location_selector = widgets.Dropdown(\n",
        "            options=[],\n",
        "            description='Location:',\n",
        "            disabled=True,\n",
        "            style={'description_width': '80px'},\n",
        "            layout=widgets.Layout(width='300px')\n",
        "        )\n",
        "\n",
        "        # === OPTIONS ===\n",
        "        self.show_details_toggle = widgets.Checkbox(\n",
        "            value=False,\n",
        "            description='Show details',\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        )\n",
        "\n",
        "        self.auto_refresh_toggle = widgets.Checkbox(\n",
        "            value=True,\n",
        "            description='Auto-refresh',\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        )\n",
        "\n",
        "        # === YEAR RANGE SELECTOR CHECKBOX ===\n",
        "        self.use_year_range_toggle = widgets.Checkbox(\n",
        "            value=False,\n",
        "            description='Use year range',\n",
        "            disabled=True,\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='150px'),\n",
        "            tooltip='Check to use start/end years, uncheck for single year'\n",
        "        )\n",
        "\n",
        "        # === ANALYSIS TYPE SELECTOR WITH DEFAULT ===\n",
        "        self.analysis_selector = widgets.Dropdown(\n",
        "            options=[\n",
        "                ('Last occurrence of value', 'last_occurrence'),\n",
        "                ('Max/Min in specific year', 'max_min_year'),\n",
        "                ('Max/Min in specific month', 'max_min_month'),\n",
        "                ('Overall max/min', 'overall_max_min'),\n",
        "                ('Last >= value', 'last_gte'),\n",
        "                ('Last <= value', 'last_lte'),\n",
        "                ('Count >= value', 'count_gte'),\n",
        "                ('Count <= value', 'count_lte'),\n",
        "                ('Wind gust frequencies', 'wind_freq'),\n",
        "                ('Seasonal precipitation', 'seasonal_precip'),\n",
        "                ('Monthly precipitation plot', 'plot_monthly'),\n",
        "                ('List occurrences above threshold', 'list_threshold'),\n",
        "                ('Top 5 winter snowfall', 'winter_snow')\n",
        "            ],\n",
        "            value='last_occurrence',\n",
        "            description='Analysis:',\n",
        "            style={'description_width': '80px'},\n",
        "            layout=widgets.Layout(width='400px')\n",
        "        )\n",
        "\n",
        "        # === COLUMN SELECTOR ===\n",
        "        self.column_selector = widgets.Dropdown(\n",
        "            options=[],\n",
        "            description='Column:',\n",
        "            disabled=True,\n",
        "            style={'description_width': '80px'},\n",
        "            layout=widgets.Layout(width='300px')\n",
        "        )\n",
        "\n",
        "        # === PARAMETER WIDGETS ===\n",
        "        self.value_input = widgets.FloatText(\n",
        "            description='Value:',\n",
        "            disabled=False,\n",
        "            style={'description_width': '60px'},\n",
        "            layout=widgets.Layout(width='180px')\n",
        "        )\n",
        "\n",
        "        self.year_input = widgets.IntText(\n",
        "            description='Year:',\n",
        "            value=2024,\n",
        "            disabled=True,\n",
        "            style={'description_width': '60px'},\n",
        "            layout=widgets.Layout(width='180px'),\n",
        "            tooltip='Single year for analysis'\n",
        "        )\n",
        "\n",
        "        self.month_selector = widgets.Dropdown(\n",
        "            options=[(calendar.month_name[i], i) for i in range(1, 13)],\n",
        "            description='Month:',\n",
        "            disabled=True,\n",
        "            style={'description_width': '60px'},\n",
        "            layout=widgets.Layout(width='200px')\n",
        "        )\n",
        "\n",
        "        self.start_year_input = widgets.IntText(\n",
        "            description='Start:',\n",
        "            value=1990,\n",
        "            disabled=True,\n",
        "            style={'description_width': '60px'},\n",
        "            layout=widgets.Layout(width='150px'),\n",
        "            tooltip='Start year for range analysis'\n",
        "        )\n",
        "\n",
        "        self.end_year_input = widgets.IntText(\n",
        "            description='End:',\n",
        "            value=2025,\n",
        "            disabled=True,\n",
        "            style={'description_width': '60px'},\n",
        "            layout=widgets.Layout(width='150px'),\n",
        "            tooltip='End year for range analysis'\n",
        "        )\n",
        "\n",
        "        self.max_min_selector = widgets.ToggleButtons(\n",
        "            options=['Max', 'Min'],\n",
        "            description='Type:',\n",
        "            disabled=True,\n",
        "            style={'description_width': '60px'},\n",
        "            layout=widgets.Layout(width='200px')\n",
        "        )\n",
        "\n",
        "        self.precip_type_selector = widgets.Dropdown(\n",
        "            options=[\n",
        "                ('Rain only', 'rain'),\n",
        "                ('Snow only', 'snow'),\n",
        "                ('Total precipitation', 'precip'),\n",
        "                ('Rain + Snow combined', 'rain_snow')\n",
        "            ],\n",
        "            description='Type:',\n",
        "            disabled=True,\n",
        "            style={'description_width': '60px'},\n",
        "            layout=widgets.Layout(width='250px')\n",
        "        )\n",
        "\n",
        "        # === ACTION BUTTONS ===\n",
        "        self.load_button = widgets.Button(\n",
        "            description='Load Data',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='150px', height='35px'),\n",
        "            tooltip='Load climate data for selected location'\n",
        "        )\n",
        "\n",
        "        self.analyze_button = widgets.Button(\n",
        "            description='Analyze',\n",
        "            button_style='success',\n",
        "            disabled=True,\n",
        "            layout=widgets.Layout(width='150px', height='35px'),\n",
        "            tooltip='Run the selected analysis'\n",
        "        )\n",
        "\n",
        "        self.clear_button = widgets.Button(\n",
        "            description='Clear',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='100px', height='35px'),\n",
        "            tooltip='Clear results'\n",
        "        )\n",
        "\n",
        "        # === Update Widgets ===\n",
        "        self.update_type_selector = widgets.RadioButtons(\n",
        "            options=[('Update Selected Location', 'single'), ('Update All Locations', 'all')],\n",
        "            value='single',\n",
        "            description='Update:',\n",
        "            disabled=True,\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "\n",
        "        self.run_update_button = widgets.Button(\n",
        "            description='Run Update',\n",
        "            button_style='info',\n",
        "            disabled=True,\n",
        "            layout=widgets.Layout(width='150px', height='35px'),\n",
        "            tooltip='Fetch and update data based on selection'\n",
        "        )\n",
        "\n",
        "        # === Navigation Widgets for Multiple Results ===\n",
        "        self.prev_result_button = widgets.Button(\n",
        "            description='Previous',\n",
        "            disabled=True,\n",
        "            layout=widgets.Layout(width='100px')\n",
        "        )\n",
        "        self.next_result_button = widgets.Button(\n",
        "            description='Next',\n",
        "            disabled=True,\n",
        "            layout=widgets.Layout(width='100px')\n",
        "        )\n",
        "        self.result_counter_label = widgets.Label(value=\"Result 0/0\")\n",
        "\n",
        "\n",
        "        # === PROGRESS BAR ===\n",
        "        self.progress_bar = widgets.IntProgress(\n",
        "            value=0,\n",
        "            min=0,\n",
        "            max=100,\n",
        "            description='Loading:',\n",
        "            style={'description_width': '60px'},\n",
        "            layout=widgets.Layout(width='300px', display='none')\n",
        "        )\n",
        "\n",
        "        # === OUTPUT AREA ===\n",
        "        self.output_area = widgets.Output(\n",
        "            layout=widgets.Layout(\n",
        "                width='auto',\n",
        "                height='auto',\n",
        "                min_height='100px',\n",
        "                max_height='600px',\n",
        "                border='1px solid var(--jp-border-color1, #ccc)',\n",
        "                overflow='auto',\n",
        "                padding='10px'\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # === RESULTS AND PLOTS PANEL (OUTER CONTAINER) ===\n",
        "        self.results_plots_panel = widgets.VBox([\n",
        "            widgets.HTML(\"<h3>📋 Results & Visualizations</h3>\"),\n",
        "            widgets.HBox([self.prev_result_button, self.result_counter_label, self.next_result_button]), # Add navigation buttons\n",
        "            self.output_area\n",
        "        ], layout=widgets.Layout(\n",
        "            border='1px solid var(--jp-border-color1, #ddd)',\n",
        "            padding='10px',\n",
        "            margin='5px',\n",
        "            width='auto' # Initialize with auto\n",
        "        ))\n",
        "\n",
        "        # Setup event handlers\n",
        "        self.setup_event_handlers()\n",
        "\n",
        "    def setup_event_handlers(self):\n",
        "        # Main event handlers\n",
        "        self.province_selector.observe(self.on_province_change, names='value')\n",
        "        self.location_selector.observe(self.on_location_change, names='value')\n",
        "        self.analysis_selector.observe(self.on_analysis_change, names='value')\n",
        "        self.column_selector.observe(self.on_column_change, names='value')\n",
        "\n",
        "        # Year range toggle handler\n",
        "        self.use_year_range_toggle.observe(self.on_year_range_toggle, names='value')\n",
        "\n",
        "        # Button handlers\n",
        "        self.load_button.on_click(self.load_data)\n",
        "        self.analyze_button.on_click(self.run_analysis)\n",
        "        self.clear_button.on_click(self.clear_output)\n",
        "        self.run_update_button.on_click(self.run_data_update) # Event handler for the new update button\n",
        "        self.update_type_selector.observe(self.on_update_type_change, names='value') # Handler for update type selection\n",
        "\n",
        "        # Navigation button handlers\n",
        "        self.prev_result_button.on_click(self.display_previous_result)\n",
        "        self.next_result_button.on_click(self.display_next_result)\n",
        "\n",
        "\n",
        "        # Auto-refresh handlers (if enabled)\n",
        "        self.value_input.observe(self.auto_analyze, names='value')\n",
        "        self.year_input.observe(self.auto_analyze, names='value')\n",
        "        self.month_selector.observe(self.auto_analyze, names='value')\n",
        "        self.use_year_range_toggle.observe(self.auto_analyze, names='value')\n",
        "\n",
        "    def resize_output_area(self, content_type='simple'):\n",
        "        \"\"\"Dynamically resize output area based on content type and call results panel resize\"\"\"\n",
        "        if content_type == 'simple':\n",
        "            # For simple results (single values, short text)\n",
        "            self.output_area.layout.width = 'auto'\n",
        "            self.output_area.layout.min_width = '400px'\n",
        "            self.output_area.layout.max_width = '600px'\n",
        "            self.output_area.layout.height = 'auto'\n",
        "            self.output_area.layout.min_height = '100px'\n",
        "            self.output_area.layout.max_height = '300px'\n",
        "            self.resize_results_panel('simple')\n",
        "        elif content_type == 'table':\n",
        "            # For tables and lists\n",
        "            self.output_area.layout.width = 'auto'\n",
        "            self.output_area.layout.min_width = '600px'\n",
        "            self.output_area.layout.max_width = '900px'\n",
        "            self.output_area.layout.height = 'auto'\n",
        "            self.output_area.layout.min_height = '200px'\n",
        "            self.output_area.layout.max_height = '500px'\n",
        "            self.resize_results_panel('table')\n",
        "        elif content_type == 'wide':\n",
        "            # For wide content like detailed statistics\n",
        "            self.output_area.layout.width = '100%'\n",
        "            self.output_area.layout.height = 'auto'\n",
        "            self.output_area.layout.min_height = '200px'\n",
        "            self.output_area.layout.max_height = '600px'\n",
        "            self.resize_results_panel('wide')\n",
        "        elif content_type == 'loading':\n",
        "            # For loading messages\n",
        "            self.output_area.layout.width = 'auto'\n",
        "            self.output_area.layout.min_width = '300px'\n",
        "            self.output_area.layout.max_width = '500px'\n",
        "            self.output_area.layout.height = 'auto'\n",
        "            self.output_area.layout.min_height = '80px'\n",
        "            self.output_area.layout.max_height = '150px'\n",
        "            self.resize_results_panel('simple') # Use simple size for loading\n",
        "        elif content_type == 'plot':\n",
        "            # For plots\n",
        "            self.output_area.layout.width = '100%'\n",
        "            self.output_area.layout.height = 'auto'\n",
        "            self.output_area.layout.min_height = '300px'\n",
        "            self.output_area.layout.max_height = '600px'\n",
        "            self.resize_results_panel('plot')\n",
        "\n",
        "    def resize_results_panel(self, content_type='simple'):\n",
        "        \"\"\"Dynamically resize the outer results panel border based on content type\"\"\"\n",
        "        if content_type == 'simple':\n",
        "            self.results_plots_panel.layout.width = 'auto'\n",
        "            self.results_plots_panel.layout.min_width = '450px'\n",
        "            self.results_plots_panel.layout.max_width = '650px'\n",
        "            self.results_plots_panel.layout.flex = '0 0 auto' # Don't grow/shrink, just take required width\n",
        "        elif content_type == 'table':\n",
        "            self.results_plots_panel.layout.width = 'auto'\n",
        "            self.results_plots_panel.layout.min_width = '650px'\n",
        "            self.results_plots_panel.layout.max_width = '950px'\n",
        "            self.results_plots_panel.layout.flex = '0 0 auto'\n",
        "        elif content_type == 'wide':\n",
        "            self.results_plots_panel.layout.width = '100%'\n",
        "            self.results_plots_panel.layout.flex = '1 1 auto' # Allow to grow and take available space\n",
        "        elif content_type == 'plot':\n",
        "             self.results_plots_panel.layout.width = '100%'\n",
        "             self.results_plots_panel.layout.flex = '1 1 auto'\n",
        "\n",
        "\n",
        "    def show_plot_area(self, show=True):\n",
        "        \"\"\"This method is no longer needed as plot is in the same area\"\"\"\n",
        "        pass\n",
        "\n",
        "    def on_year_range_toggle(self, change):\n",
        "        \"\"\"Handle year range checkbox toggle\"\"\"\n",
        "        use_range = change['new']\n",
        "        analysis = self.analysis_selector.value\n",
        "\n",
        "        # Only affect count analyses\n",
        "        if analysis in ['count_gte', 'count_lte']:\n",
        "            if use_range:\n",
        "                # Enable range inputs, disable single year\n",
        "                self.start_year_input.disabled = False\n",
        "                self.end_year_input.disabled = False\n",
        "                self.year_input.disabled = True\n",
        "            else:\n",
        "                # Enable single year, disable range inputs\n",
        "                self.year_input.disabled = False\n",
        "                self.start_year_input.disabled = True\n",
        "                self.end_year_input.disabled = True\n",
        "\n",
        "    def on_province_change(self, change):\n",
        "        province = change['new']\n",
        "        self.current_province = province\n",
        "        folder_path = f\"{self.base_folder_path}/{province}\"\n",
        "\n",
        "        try:\n",
        "            self.locations = get_locations_from_csv(folder_path)\n",
        "            location_options = [('All Locations', 'ALL')] + [(loc, loc) for loc in sorted(self.locations)]\n",
        "            self.location_selector.options = location_options\n",
        "            self.location_selector.disabled = False\n",
        "            self.location_selector.value = None\n",
        "            self.update_type_selector.disabled = False # Enable update options when province changes\n",
        "            self.on_update_type_change({'new': self.update_type_selector.value}) # Trigger update button state based on default selection\n",
        "\n",
        "        except Exception as e:\n",
        "            self.location_selector.options = []\n",
        "            self.location_selector.disabled = True\n",
        "            self.update_type_selector.disabled = True\n",
        "            self.run_update_button.disabled = True\n",
        "            self.resize_output_area('simple')\n",
        "            with self.output_area:\n",
        "                clear_output()\n",
        "                print(f\"Error loading locations: {str(e)}\")\n",
        "\n",
        "    def on_location_change(self, change):\n",
        "        if change['new'] is not None:\n",
        "            self.load_button.disabled = False\n",
        "            # Re-evaluate update button state based on new location selection\n",
        "            self.on_update_type_change({'new': self.update_type_selector.value})\n",
        "\n",
        "\n",
        "    def on_update_type_change(self, change):\n",
        "        \"\"\"Handle change in update type selector (single vs all)\"\"\"\n",
        "        update_type = change['new']\n",
        "        location = self.location_selector.value\n",
        "\n",
        "        if update_type == 'single':\n",
        "            # Enable update button only if a specific location is selected\n",
        "            self.run_update_button.disabled = (location == 'ALL' or location is None)\n",
        "        elif update_type == 'all':\n",
        "            # Enable update button if province is selected and there are locations\n",
        "            self.run_update_button.disabled = (self.current_province is None or not self.locations)\n",
        "\n",
        "\n",
        "    def on_analysis_change(self, change):\n",
        "        analysis = change['new']\n",
        "\n",
        "        # Reset all parameter widgets\n",
        "        param_widgets = [\n",
        "            self.value_input, self.year_input, self.month_selector,\n",
        "            self.start_year_input, self.end_year_input, self.max_min_selector,\n",
        "            self.precip_type_selector, self.use_year_range_toggle\n",
        "        ]\n",
        "\n",
        "        for widget in param_widgets:\n",
        "            widget.disabled = True\n",
        "\n",
        "        # Enable relevant widgets based on analysis type\n",
        "        if analysis in ['last_occurrence', 'last_gte', 'last_lte', 'list_threshold', 'overall_max_min', 'max_min_year', 'min_in_year', 'max_in_month', 'min_in_month']: # Added overall_max_min, max_min_year, etc. here\n",
        "            self.value_input.disabled = False # Value input can be used for filtering even if not required by lookup_data\n",
        "\n",
        "        if analysis in ['count_gte', 'count_lte']:\n",
        "            self.value_input.disabled = False\n",
        "            self.use_year_range_toggle.disabled = False\n",
        "\n",
        "            # Set initial state based on checkbox\n",
        "            if self.use_year_range_toggle.value:\n",
        "                self.start_year_input.disabled = False\n",
        "                self.end_year_input.disabled = False\n",
        "            else:\n",
        "                self.year_input.disabled = False\n",
        "\n",
        "        if analysis in ['max_min_year', 'seasonal_precip', 'winter_snow']:\n",
        "            self.year_input.disabled = False\n",
        "\n",
        "        if analysis in ['max_min_year', 'max_min_month', 'overall_max_min']:\n",
        "            self.max_min_selector.disabled = False\n",
        "\n",
        "        if analysis == 'max_min_month':\n",
        "            self.month_selector.disabled = False\n",
        "\n",
        "        if analysis in ['wind_freq', 'list_threshold', 'plot_monthly']: # Added list_threshold and plot_monthly here\n",
        "            self.start_year_input.disabled = False\n",
        "            self.end_year_input.disabled = False\n",
        "\n",
        "        if analysis == 'plot_monthly':\n",
        "            self.month_selector.disabled = False\n",
        "            self.precip_type_selector.disabled = False\n",
        "\n",
        "        # Update column options based on analysis\n",
        "        self.update_column_options(analysis)\n",
        "\n",
        "        # Reset navigation state when analysis type changes\n",
        "        self.analysis_results = [] # Reset to empty list\n",
        "        self.current_result_index = 0\n",
        "        self.update_navigation_buttons()\n",
        "\n",
        "\n",
        "    def update_column_options(self, analysis):\n",
        "        if self.df is None:\n",
        "            return\n",
        "\n",
        "        if analysis in ['wind_freq']:\n",
        "            # Auto-select wind gust column\n",
        "            self.column_selector.options = [(\"Wind Gust Speed\", \"Spd of Max Gust (km/h)\")]\n",
        "            self.column_selector.value = \"Spd of Max Gust (km/h)\"\n",
        "            self.column_selector.disabled = True\n",
        "\n",
        "        elif analysis in ['seasonal_precip', 'plot_monthly']:\n",
        "            # Precipitation columns only\n",
        "            precip_cols = [col for col in self.df.columns\n",
        "                          if any(x in col for x in ['Precip', 'Snow', 'Rain'])]\n",
        "            self.column_selector.options = [(col, col) for col in precip_cols]\n",
        "            self.column_selector.disabled = False\n",
        "\n",
        "        elif analysis == 'winter_snow':\n",
        "            # Auto-select snow column\n",
        "            self.column_selector.options = [(\"Total Snow\", \"Total Snow (cm)\")]\n",
        "            self.column_selector.value = \"Total Snow (cm)\"\n",
        "            self.column_selector.disabled = True\n",
        "\n",
        "        else:\n",
        "            # All numeric weather columns\n",
        "            weather_cols = [col for col in self.df.columns\n",
        "                           if any(x in col for x in ['Temp', 'Precip', 'Snow', 'Rain', 'Gust'])]\n",
        "            self.column_selector.options = [(col, col) for col in weather_cols]\n",
        "            self.column_selector.disabled = False\n",
        "\n",
        "\n",
        "    def on_column_change(self, change):\n",
        "        if self.auto_refresh_toggle.value and change['new'] is not None:\n",
        "            self.auto_analyze()\n",
        "\n",
        "    def auto_analyze(self, change=None):\n",
        "        if (self.auto_refresh_toggle.value and\n",
        "            self.df is not None and\n",
        "            not self.analyze_button.disabled):\n",
        "            self.run_analysis(None)\n",
        "\n",
        "    def load_data(self, button):\n",
        "        self.resize_output_area('loading')\n",
        "        self.progress_bar.layout.display = 'block'\n",
        "        self.progress_bar.value = 20\n",
        "\n",
        "        with self.output_area:\n",
        "            clear_output()\n",
        "            print(\"Loading climate data...\")\n",
        "\n",
        "        try:\n",
        "            province = self.province_selector.value\n",
        "            location = self.location_selector.value\n",
        "\n",
        "            self.progress_bar.value = 40\n",
        "\n",
        "            if location == 'ALL':\n",
        "                # Load all locations\n",
        "                dfs = []\n",
        "                for i, loc in enumerate(self.locations):\n",
        "                    try:\n",
        "                        csv_path = f\"{self.base_folder_path}/{province}/{loc}_daily_data.csv\"\n",
        "                        df_temp = pd.read_csv(csv_path)\n",
        "                        dfs.append(df_temp)\n",
        "                        self.progress_bar.value = 40 + (i / len(self.locations)) * 40\n",
        "                    except:\n",
        "                        continue\n",
        "                self.df = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
        "            else:\n",
        "                csv_file_path = f\"{self.base_folder_path}/{province}/{location}_daily_data.csv\"\n",
        "                self.df = pd.read_csv(csv_file_path)\n",
        "\n",
        "            self.progress_bar.value = 80\n",
        "\n",
        "            if self.df.empty:\n",
        "                raise ValueError(\"No data found\")\n",
        "\n",
        "            # Process data\n",
        "            if 'Date/Time' in self.df.columns:\n",
        "                self.df['Date/Time'] = pd.to_datetime(self.df['Date/Time'])\n",
        "\n",
        "            if 'Year' not in self.df.columns:\n",
        "                self.df['Year'] = self.df['Date/Time'].dt.year\n",
        "            if 'Month' not in self.df.columns:\n",
        "                self.df['Month'] = self.df['Date/Time'].dt.month\n",
        "\n",
        "            self.progress_bar.value = 90\n",
        "\n",
        "            # Update column options\n",
        "            self.update_column_options(self.analysis_selector.value)\n",
        "            self.analyze_button.disabled = False\n",
        "\n",
        "            self.progress_bar.value = 100\n",
        "\n",
        "            # Resize for simple summary display\n",
        "            if self.show_details_toggle.value:\n",
        "                self.resize_output_area('table')\n",
        "            else:\n",
        "                self.resize_output_area('simple')\n",
        "\n",
        "            # Display summary\n",
        "            with self.output_area:\n",
        "                clear_output() # Clear the 'Loading climate data...' message\n",
        "                print(\"Data loaded successfully!\")\n",
        "                print(f\"Records: {len(self.df):,}\")\n",
        "                print(f\"Period: {self.df['Date/Time'].min().date()} to {self.df['Date/Time'].max().date()}\")\n",
        "                print(f\"Location: {location or 'All locations'}\")\n",
        "                print(f\"Province: {province}\")\n",
        "\n",
        "                if self.show_details_toggle.value:\n",
        "                    print(f\"\\nAvailable columns:\")\n",
        "                    for col in sorted(self.df.columns):\n",
        "                        if any(x in col for x in ['Temp', 'Precip', 'Snow', 'Rain', 'Gust']):\n",
        "                            print(f\"  • {col}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.resize_output_area('simple')\n",
        "            with self.output_area:\n",
        "                clear_output() # Clear the 'Loading climate data...' message\n",
        "                print(f\"Error loading data: {e}\")\n",
        "\n",
        "        finally:\n",
        "            self.progress_bar.layout.display = 'none'\n",
        "            self.progress_bar.value = 0\n",
        "\n",
        "    def run_data_update(self, button):\n",
        "        \"\"\"Handles the logic for updating either a single file or all files.\"\"\"\n",
        "        update_type = self.update_type_selector.value\n",
        "        province = self.province_selector.value\n",
        "\n",
        "        # Ensure output area is cleared and resized for loading state before running update\n",
        "        self.resize_output_area('loading')\n",
        "        with self.output_area:\n",
        "             clear_output()\n",
        "\n",
        "        if update_type == 'single':\n",
        "            location = self.location_selector.value\n",
        "            if location == 'ALL' or location is None:\n",
        "                self.resize_output_area('simple')\n",
        "                with self.output_area:\n",
        "                    print(\"Please select a specific location to update.\")\n",
        "                return\n",
        "\n",
        "            csv_file_path = f\"{self.base_folder_path}/{province}/{location}_daily_data.csv\"\n",
        "            self.update_single_location(csv_file_path, location, province)\n",
        "\n",
        "        elif update_type == 'all':\n",
        "            base_dir = f\"{self.base_folder_path}/{province}\"\n",
        "            self.update_all_locations(base_dir, province)\n",
        "\n",
        "\n",
        "    def update_single_location(self, file_path, location_name, province):\n",
        "        \"\"\"Updates a single CSV file with the most recent data.\"\"\"\n",
        "        # Output is captured by the with statement in run_data_update\n",
        "        with self.output_area: # Wrap calls that print to stdout\n",
        "            print(f\"Starting update for {location_name}, {province}...\")\n",
        "            try:\n",
        "                update_csv_file(file_path) # Call the original function\n",
        "                # After update, reload the data if it was the currently loaded location\n",
        "                if self.location_selector.value == location_name and self.province_selector.value == province:\n",
        "                     # Clear just the update messages before showing the load summary\n",
        "                     # This is a bit tricky with clear_output, might need a separate output area\n",
        "                     # For now, let's just print the load summary after the update messages\n",
        "                     self.load_data(None) # Reload the data for the currently selected location\n",
        "                     print(\"Reloaded data for the selected location.\")\n",
        "\n",
        "\n",
        "            except Exception as e:\n",
        "                # The outer run_data_update catch will handle errors and resize\n",
        "                print(f\"Error updating data for {location_name}, {province}: {e}\") # Print error within output area\n",
        "\n",
        "    def update_all_locations(self, base_dir, province):\n",
        "        \"\"\"Updates all CSV files in a given province.\"\"\"\n",
        "        # Output is captured by the with statement in run_data_update\n",
        "        with self.output_area: # Wrap calls that print to stdout\n",
        "            print(f\"Starting update for all locations in {province}...\")\n",
        "\n",
        "            if not os.path.exists(base_dir):\n",
        "                # The outer run_data_update catch will handle errors and resize\n",
        "                print(f\"Error: Directory {base_dir} not found.\")\n",
        "                return\n",
        "\n",
        "            all_csv_files = glob.glob(os.path.join(base_dir, \"*.csv\"))\n",
        "\n",
        "            if not all_csv_files:\n",
        "                # The outer run_data_update catch will handle errors and resize\n",
        "                print(f\"No CSV files found in {base_dir}.\")\n",
        "                return\n",
        "\n",
        "            print(f\"Found {len(all_csv_files)} CSV files to update.\")\n",
        "\n",
        "            for i, file_path in enumerate(all_csv_files, 1):\n",
        "                location_name = os.path.basename(file_path).replace('_daily_data.csv', '')\n",
        "                print(f\"\\nUpdating file {i}/{len(all_csv_files)}: {location_name}...\")\n",
        "\n",
        "                try:\n",
        "                    update_csv_file(file_path) # Call the original function\n",
        "                    print(f\"Update for {location_name} completed.\")\n",
        "                except Exception as e:\n",
        "                    # The outer run_data_update catch will handle errors and resize\n",
        "                    print(f\"Error updating {location_name}: {str(e)}\")\n",
        "\n",
        "            print(f\"\\nAll files in {province} have been updated.\")\n",
        "            # If 'ALL' was the selected location, reload the concatenated data\n",
        "            if self.location_selector.value == 'ALL' and self.province_selector.value == province:\n",
        "                 self.load_data(None)\n",
        "                 print(\"Reloaded data for all locations.\")\n",
        "\n",
        "\n",
        "    def run_analysis(self, button):\n",
        "        if self.df is None:\n",
        "            self.resize_output_area('simple')\n",
        "            with self.output_area:\n",
        "                clear_output()\n",
        "                print(\"Please load data first\")\n",
        "            return\n",
        "\n",
        "        analysis = self.analysis_selector.value\n",
        "\n",
        "        # Determine appropriate sizing for analysis type\n",
        "        if analysis in ['wind_freq', 'list_threshold', 'seasonal_precip', 'winter_snow']:\n",
        "            self.resize_output_area('table')\n",
        "        elif analysis == 'plot_monthly':\n",
        "            self.resize_output_area('plot')\n",
        "        elif analysis == 'overall_max_min' and self.show_details_toggle.value:\n",
        "             self.resize_output_area('table') # Expand for additional results\n",
        "        else:\n",
        "            self.resize_output_area('simple')\n",
        "\n",
        "\n",
        "        with self.output_area:\n",
        "            clear_output()\n",
        "            print(f\"Running analysis...\")\n",
        "\n",
        "            try:\n",
        "                # Route to appropriate analysis method\n",
        "                if analysis == 'last_occurrence':\n",
        "                    self.analyze_last_occurrence()\n",
        "                elif analysis == 'overall_max_min':\n",
        "                    self.analyze_overall_max_min()\n",
        "                elif analysis == 'max_min_year':\n",
        "                    self.analyze_max_min_year()\n",
        "                elif analysis == 'max_min_month':\n",
        "                    self.analyze_max_min_month()\n",
        "                elif analysis in ['last_gte', 'last_lte']:\n",
        "                    self.analyze_last_comparison()\n",
        "                elif analysis in ['count_gte', 'count_lte']:\n",
        "                    self.analyze_count_comparison()\n",
        "                elif analysis == 'wind_freq':\n",
        "                    self.analyze_wind_frequencies()\n",
        "                elif analysis == 'seasonal_precip':\n",
        "                    self.analyze_seasonal_precipitation()\n",
        "                elif analysis == 'plot_monthly':\n",
        "                    self.plot_monthly_precipitation()\n",
        "                elif analysis == 'list_threshold':\n",
        "                    self.list_threshold_occurrences()\n",
        "                elif analysis == 'winter_snow':\n",
        "                    self.analyze_winter_snowfall()\n",
        "\n",
        "            except Exception as e:\n",
        "                clear_output() # Clear the \"Running analysis...\" message\n",
        "                print(f\"Error running analysis: {e}\")\n",
        "\n",
        "    def analyze_last_occurrence(self):\n",
        "        value = self.value_input.value\n",
        "        column = self.column_selector.value\n",
        "        location = self.location_selector.value if self.location_selector.value != 'ALL' else None\n",
        "\n",
        "        # Get all occurrences and store them\n",
        "        all_matches = lookup_data(self.df, column, 'all_occurrences', value, location)\n",
        "        self.analysis_results = all_matches.sort_values(by='Date/Time', ascending=False).reset_index(drop=True).to_dict('records') # Store as list of dicts\n",
        "        self.current_result_index = 0 # Start with the last occurrence\n",
        "\n",
        "        self.display_current_result() # Display the first result\n",
        "\n",
        "    def analyze_overall_max_min(self):\n",
        "        \"\"\"Find overall max/min and store all matching occurrences.\"\"\"\n",
        "        column = self.column_selector.value\n",
        "        lookup_type = self.max_min_selector.value.lower()\n",
        "        location = self.location_selector.value if self.location_selector.value != 'ALL' else None\n",
        "\n",
        "        # Filter data based on location if specified\n",
        "        data = self.df.copy()\n",
        "        if location is not None:\n",
        "            data = data[data['Station Name'].str.lower() == location.lower()]\n",
        "\n",
        "        if data.empty:\n",
        "            self.analysis_results = [] # Store as empty list\n",
        "            self.current_result_index = 0\n",
        "            self.display_current_result()\n",
        "            return\n",
        "\n",
        "        # Convert the column to numeric, coercing errors to NaN\n",
        "        data[column] = pd.to_numeric(data[column], errors='coerce')\n",
        "        data = data.dropna(subset=[column]) # Remove rows with NaN in the target column\n",
        "\n",
        "        if data.empty:\n",
        "            self.analysis_results = [] # Store as empty list\n",
        "            self.current_result_index = 0\n",
        "            self.display_current_result()\n",
        "            return\n",
        "\n",
        "        # Find unique extreme values and get their occurrences\n",
        "        if lookup_type == 'max':\n",
        "            # Sort by the column descending to get max values first\n",
        "            sorted_data = data.sort_values(by=column, ascending=False)\n",
        "        else: # lookup_type == 'min'\n",
        "            # Sort by the column ascending to get min values first\n",
        "            sorted_data = data.sort_values(by=column, ascending=True)\n",
        "\n",
        "        # Get the top 20 distinct values\n",
        "        distinct_values = sorted_data[column].unique()[:20]\n",
        "\n",
        "        # Store results as a list of dictionaries, where each dict contains the value and its occurrences\n",
        "        structured_results = []\n",
        "        for value in distinct_values:\n",
        "            occurrences = sorted_data[sorted_data[column] == value].to_dict('records')\n",
        "            structured_results.append({\n",
        "                'value': value,\n",
        "                'occurrences': occurrences\n",
        "            })\n",
        "\n",
        "        # Store the structured results in analysis_results (as a list of dicts)\n",
        "        self.analysis_results = structured_results\n",
        "        self.current_result_index = 0 # Start with the first distinct extreme value\n",
        "\n",
        "        self.display_current_result() # Display the first result\n",
        "\n",
        "\n",
        "    def analyze_max_min_year(self):\n",
        "        \"\"\"Find max/min in specific year and store all matching occurrences.\"\"\"\n",
        "        year = self.year_input.value\n",
        "        column = self.column_selector.value\n",
        "        lookup_type = self.max_min_selector.value.lower()\n",
        "        location = self.location_selector.value if self.location_selector.value != 'ALL' else None\n",
        "\n",
        "        # Get all occurrences matching the max/min in the year\n",
        "        all_matches = lookup_data(self.df, column, f'{lookup_type}_in_year', year=year, location=location)\n",
        "        self.analysis_results = all_matches.sort_values(by='Date/Time').reset_index(drop=True).to_dict('records') # Store as list of dicts\n",
        "        self.current_result_index = 0 # Start with the earliest occurrence\n",
        "\n",
        "        self.display_current_result() # Display the first result\n",
        "\n",
        "\n",
        "    def analyze_max_min_month(self):\n",
        "        \"\"\"Find max/min in specific month and store all matching occurrences.\"\"\"\n",
        "        month = self.month_selector.value\n",
        "        column = self.column_selector.value\n",
        "        lookup_type = self.max_min_selector.value.lower()\n",
        "        location = self.location_selector.value if self.location_selector.value != 'ALL' else None\n",
        "\n",
        "        # Get all occurrences matching the max/min in the month\n",
        "        all_matches = lookup_data(self.df, column, f'{lookup_type}_in_month', month=month, location=location)\n",
        "        self.analysis_results = all_matches.sort_values(by='Date/Time').reset_index(drop=True).to_dict('records') # Store as list of dicts\n",
        "        self.current_result_index = 0 # Start with the earliest occurrence\n",
        "\n",
        "        self.display_current_result() # Display the first result\n",
        "\n",
        "\n",
        "    def analyze_last_comparison(self):\n",
        "        \"\"\"Analyze last occurrence greater/less than value and store all matching occurrences.\"\"\"\n",
        "        value = self.value_input.value\n",
        "        column = self.column_selector.value\n",
        "        location = self.location_selector.value if self.location_selector.value != 'ALL' else None\n",
        "        analysis = self.analysis_selector.value\n",
        "\n",
        "        lookup_type = 'all_greater_than_or_equal' if analysis == 'last_gte' else 'all_less_than_or_equal'\n",
        "        operator = '>=' if analysis == 'last_gte' else '<='\n",
        "\n",
        "        # Get all occurrences and store them\n",
        "        all_matches = lookup_data(self.df, column, lookup_type, value, location)\n",
        "        self.analysis_results = all_matches.sort_values(by='Date/Time', ascending=False).reset_index(drop=True).to_dict('records') # Store as list of dicts\n",
        "        self.current_result_index = 0 # Start with the last occurrence\n",
        "\n",
        "        self.display_current_result() # Display the first result\n",
        "\n",
        "    def display_current_result(self):\n",
        "        \"\"\"Displays the details of the current result from analysis_results.\"\"\"\n",
        "        with self.output_area:\n",
        "            clear_output()\n",
        "            if not self.analysis_results: # Check if the list is empty\n",
        "                print(\"No results found for this analysis.\")\n",
        "                self.result_counter_label.value = \"Result 0/0\"\n",
        "                self.update_navigation_buttons()\n",
        "                return\n",
        "\n",
        "            total_results = len(self.analysis_results)\n",
        "            current_index = self.current_result_index\n",
        "\n",
        "            analysis = self.analysis_selector.value\n",
        "            column = self.column_selector.value\n",
        "            location = self.location_selector.value if self.location_selector.value != 'ALL' else None\n",
        "\n",
        "            # Update result counter label\n",
        "            self.result_counter_label.value = f\"Result {current_index + 1}/{total_results}\"\n",
        "\n",
        "            # Display header based on analysis type\n",
        "            if analysis in ['last_occurrence', 'last_gte', 'last_lte', 'max_min_year', 'max_min_month']:\n",
        "                 current_row = self.analysis_results[current_index] # Access as list of dicts\n",
        "                 date = pd.to_datetime(current_row['Date/Time']).strftime('%Y-%m-%d')\n",
        "                 value = current_row[column]\n",
        "                 station = current_row['Station Name'] if 'Station Name' in current_row else 'N/A'\n",
        "\n",
        "                 if analysis == 'last_occurrence':\n",
        "                      search_value = self.value_input.value\n",
        "                      print(f\"Occurrence Analysis (Value = {search_value})\")\n",
        "                      print(f\"Looking for: {column} = {search_value}\")\n",
        "                 elif analysis in ['last_gte', 'last_lte']:\n",
        "                      search_value = self.value_input.value\n",
        "                      operator = '>=' if analysis == 'last_gte' else '<='\n",
        "                      print(f\"Occurrence Analysis ({operator} {search_value})\")\n",
        "                      print(f\"Looking for: {column} {operator} {search_value}\")\n",
        "                 elif analysis in ['max_min_year', 'max_min_month']:\n",
        "                      lookup_type = self.max_min_selector.value.lower()\n",
        "                      year = self.year_input.value if analysis == 'max_min_year' else 'N/A'\n",
        "                      month = calendar.month_name[self.month_selector.value] if analysis == 'max_min_month' else 'N/A'\n",
        "                      print(f\"{lookup_type.capitalize()} Occurrence Analysis\")\n",
        "                      print(f\"Column: {column}\")\n",
        "                      if analysis == 'max_min_year': print(f\"Year: {year}\")\n",
        "                      if analysis == 'max_min_month': print(f\"Month: {month}\")\n",
        "\n",
        "                 print(f\"Location: {location or 'All locations'}\")\n",
        "                 print(\"-\" * 40)\n",
        "\n",
        "                 print(f\"Date: {date}\")\n",
        "                 print(f\"Value: {value}\")\n",
        "                 if not location: # Only show station name if not filtered by a specific location\n",
        "                      print(f\"Station: {station}\")\n",
        "\n",
        "\n",
        "            elif analysis == 'overall_max_min':\n",
        "                 lookup_type = self.max_min_selector.value.lower()\n",
        "                 print(f\"Overall {lookup_type.capitalize()} Analysis\")\n",
        "                 print(f\"Column: {column}\")\n",
        "                 print(f\"Location: {location or 'All locations'}\")\n",
        "                 print(\"-\" * 40)\n",
        "\n",
        "                 # Display details for the current distinct extreme value\n",
        "                 current_extreme_data = self.analysis_results[current_index]\n",
        "                 extreme_value = current_extreme_data['value']\n",
        "                 occurrences = current_extreme_data['occurrences']\n",
        "\n",
        "                 print(f\"Value: {extreme_value}\")\n",
        "                 print(f\"Occurrences ({len(occurrences)}):\")\n",
        "\n",
        "                 # Display occurrences in a table\n",
        "                 table_data = []\n",
        "                 for occ in occurrences:\n",
        "                     date = pd.to_datetime(occ['Date/Time']).strftime('%Y-%m-%d')\n",
        "                     if location:\n",
        "                         table_data.append([date])\n",
        "                     else:\n",
        "                         table_data.append([date, occ['Station Name']])\n",
        "\n",
        "                 headers = [\"Date\"] if location else [\"Date\", \"Station\"]\n",
        "                 print(tabulate(table_data, headers=headers, tablefmt=\"plain\")) # Use plain format for cleaner list\n",
        "\n",
        "\n",
        "            # Update navigation button states\n",
        "            self.update_navigation_buttons()\n",
        "\n",
        "\n",
        "    def display_previous_result(self, button):\n",
        "        \"\"\"Displays the previous result if available.\"\"\"\n",
        "        if self.current_result_index > 0:\n",
        "            self.current_result_index -= 1\n",
        "            self.display_current_result()\n",
        "\n",
        "    def display_next_result(self, button):\n",
        "        \"\"\"Displays the next result if available.\"\"\"\n",
        "        if self.current_result_index < len(self.analysis_results) - 1:\n",
        "            self.current_result_index += 1\n",
        "            self.display_current_result()\n",
        "\n",
        "    def update_navigation_buttons(self):\n",
        "        \"\"\"Enables/disables navigation buttons based on current result index.\"\"\"\n",
        "        total_results = len(self.analysis_results)\n",
        "        self.prev_result_button.disabled = (self.current_result_index <= 0) or (total_results <= 1)\n",
        "        self.next_result_button.disabled = (self.current_result_index >= total_results - 1) or (total_results <= 1)\n",
        "        self.result_counter_label.value = f\"Result {self.current_result_index + 1}/{total_results}\" if total_results > 0 else \"Result 0/0\"\n",
        "\n",
        "\n",
        "    def analyze_wind_frequencies(self):\n",
        "        \"\"\"Analyze wind gust frequencies with table sizing\"\"\"\n",
        "        start_year = self.start_year_input.value\n",
        "        end_year = self.end_year_input.value\n",
        "        location = self.location_selector.value if self.location_selector.value != 'ALL' else None\n",
        "        gust_column = \"Spd of Max Gust (km/h)\"\n",
        "\n",
        "        # Filter data\n",
        "        filtered_df = self.df.copy()\n",
        "        if start_year > 0:\n",
        "            filtered_df = filtered_df[filtered_df['Date/Time'].dt.year >= start_year]\n",
        "        if end_year > 0:\n",
        "            filtered_df = filtered_df[filtered_df['Date/Time'].dt.year <= end_year]\n",
        "        if location:\n",
        "            filtered_df = filtered_df[filtered_df['Station Name'] == location]\n",
        "\n",
        "        # Convert to numeric\n",
        "        filtered_df[gust_column] = pd.to_numeric(filtered_df[gust_column], errors='coerce')\n",
        "        filtered_df = filtered_df.dropna(subset=[gust_column])\n",
        "\n",
        "        # This method is already wrapped in with self.output_area: in run_analysis\n",
        "        clear_output()\n",
        "        print(f\"Wind Gust Frequency Analysis\")\n",
        "        print(f\"Period: {start_year}-{end_year}\")\n",
        "        print(f\"Location: {location or 'All locations'}\")\n",
        "        print(f\"Total records: {len(filtered_df)}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Calculate frequencies for different thresholds\n",
        "        thresholds = [80, 90, 100, 110, 120, 130, 140, 150]\n",
        "        total_years = end_year - start_year + 1 if start_year > 0 and end_year > 0 else 1 # Handle case with no year range\n",
        "\n",
        "        table_data = []\n",
        "        for threshold in thresholds:\n",
        "            count = len(filtered_df[filtered_df[gust_column] >= threshold])\n",
        "            if count > 0:\n",
        "                if total_years > 0: # Avoid division by zero\n",
        "                    freq_per_year = count / total_years\n",
        "\n",
        "                    # Format frequency\n",
        "                    if freq_per_year >= 1:\n",
        "                        frequency_str = f\"{freq_per_year:.1f} per year\"\n",
        "                    elif freq_per_year * 10 >= 1:\n",
        "                        frequency_str = f\"{freq_per_year * 10:.1f} per decade\"\n",
        "                    else:\n",
        "                        frequency_str = f\"{freq_per_year * 100:.1f} per century\"\n",
        "                else:\n",
        "                     frequency_str = \"N/A (No years in range)\"\n",
        "\n",
        "\n",
        "                table_data.append([f\">={threshold} km/h\", count, frequency_str])\n",
        "\n",
        "        if table_data:\n",
        "            print(tabulate(table_data, headers=[\"Threshold\", \"Count\", \"Frequency\"], tablefmt=\"grid\"))\n",
        "\n",
        "        # Top 5 gusts\n",
        "        top_5 = filtered_df.nlargest(5, gust_column)\n",
        "        print(f\"\\nTop 5 Wind Gusts:\")\n",
        "        for i, (_, row) in enumerate(top_5.iterrows(), 1):\n",
        "            date = row['Date/Time'].strftime('%Y-%m-%d')\n",
        "            print(f\"  {i}. {row[gust_column]:.1f} km/h on {date}\")\n",
        "\n",
        "\n",
        "    def find_next_extremes(self, column, lookup_type, location, current_value, current_date, num_additional=4):\n",
        "        \"\"\"Find the next highest/lowest values\"\"\"\n",
        "        found_dates = {pd.to_datetime(current_date).date()}\n",
        "\n",
        "        # This method is called within analyze_overall_max_min, which is wrapped\n",
        "        for i in range(1, num_additional + 1):\n",
        "            df_filtered = self.df.copy()\n",
        "            df_filtered[column] = pd.to_numeric(df_filtered[column], errors='coerce')\n",
        "\n",
        "            # Filter out previously found dates\n",
        "            mask = ~df_filtered['Date/Time'].dt.date.isin(found_dates)\n",
        "            if location:\n",
        "                mask &= (df_filtered['Station Name'] == location)\n",
        "\n",
        "            filtered_df = df_filtered[mask]\n",
        "\n",
        "            if filtered_df.empty:\n",
        "                break\n",
        "\n",
        "            if lookup_type == 'max':\n",
        "                next_idx = filtered_df[column].idxmax()\n",
        "            else:\n",
        "                next_idx = filtered_df[column].idxmin()\n",
        "\n",
        "            next_row = filtered_df.loc[next_idx]\n",
        "            next_value = next_row[column]\n",
        "            next_date = next_row['Date/Time'].date()\n",
        "\n",
        "            print(f\"#{i+1}: {next_value} on {next_date}\")\n",
        "            found_dates.add(next_date)\n",
        "\n",
        "\n",
        "    def analyze_count_comparison(self):\n",
        "        \"\"\"Count occurrences greater/less than value with checkbox-controlled year selection\"\"\"\n",
        "        value = self.value_input.value\n",
        "        column = self.column_selector.value\n",
        "        location = self.location_selector.value if self.location_selector.value != 'ALL' else None\n",
        "        analysis = self.analysis_selector.value\n",
        "\n",
        "        # Get year parameters based on checkbox\n",
        "        use_range = self.use_year_range_toggle.value\n",
        "\n",
        "        lookup_type = 'count_greater_than_or_equal' if analysis == 'count_gte' else 'count_less_than_or_equal'\n",
        "        operator = '>=' if analysis == 'count_gte' else '<='\n",
        "\n",
        "        # Filter data based on year selection\n",
        "        filtered_df = self.df.copy()\n",
        "        if location:\n",
        "            filtered_df = filtered_df[filtered_df['Station Name'] == location]\n",
        "\n",
        "        if use_range:\n",
        "            start_year = self.start_year_input.value\n",
        "            end_year = self.end_year_input.value\n",
        "            filtered_df = filtered_df[\n",
        "                (filtered_df['Date/Time'].dt.year >= start_year) &\n",
        "                (filtered_df['Date/Time'].dt.year <= end_year)\n",
        "            ]\n",
        "            year_description = f\"Period: {start_year}-{end_year}\"\n",
        "        else:\n",
        "            single_year = self.year_input.value\n",
        "            filtered_df = filtered_df[filtered_df['Date/Time'].dt.year == single_year]\n",
        "            year_description = f\"Year: {single_year}\"\n",
        "\n",
        "        # Convert to numeric and apply threshold\n",
        "        filtered_df[column] = pd.to_numeric(filtered_df[column], errors='coerce')\n",
        "\n",
        "        if analysis == 'count_gte':\n",
        "            result_df = filtered_df[filtered_df[column] >= value]\n",
        "        else:\n",
        "            result_df = filtered_df[filtered_df[column] <= value]\n",
        "\n",
        "        result_count = len(result_df)\n",
        "        total_records = len(filtered_df[filtered_df[column].notna()])\n",
        "\n",
        "        # This method is already wrapped in with self.output_area: in run_analysis\n",
        "        clear_output()\n",
        "        print(f\"Count {operator} Analysis\")\n",
        "        print(f\"Counting: {column} {operator} {value}\")\n",
        "        print(f\"Location: {location or 'All locations'}\")\n",
        "        print(f\"{year_description}\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Total occurrences: {result_count}\")\n",
        "        print(f\"Total records: {total_records}\")\n",
        "        if total_records > 0:\n",
        "            percentage = (result_count / total_records) * 100\n",
        "            print(f\"Percentage: {percentage:.1f}%\")\n",
        "\n",
        "        # Show additional details if enabled\n",
        "        if self.show_details_toggle.value and result_count > 0:\n",
        "            print(f\"\\nAdditional Details:\")\n",
        "\n",
        "            # Show yearly breakdown for ranges\n",
        "            if use_range:\n",
        "                yearly_counts = result_df.groupby(result_df['Date/Time'].dt.year).size()\n",
        "                print(f\"\\nYearly breakdown:\")\n",
        "                for year, count in yearly_counts.items():\n",
        "                    year_total = len(filtered_df[\n",
        "                        (filtered_df['Date/Time'].dt.year == year) &\n",
        "                        (filtered_df[column].notna())\n",
        "                    ])\n",
        "                    if year_total > 0:\n",
        "                        year_pct = (count / year_total) * 100\n",
        "                        print(f\"  {year}: {count} occurrences ({year_pct:.1f}%)\")\n",
        "\n",
        "            # Show monthly breakdown for single year\n",
        "            else:\n",
        "                monthly_counts = result_df.groupby(result_df['Date/Time'].dt.month).size()\n",
        "                single_year = self.year_input.value\n",
        "                print(f\"\\nMonthly breakdown for {single_year}:\")\n",
        "                for month, count in monthly_counts.items():\n",
        "                    month_total = len(filtered_df[\n",
        "                        (filtered_df['Date/Time'].dt.month == month) &\n",
        "                        (filtered_df[column].notna())\n",
        "                    ])\n",
        "                    if month_total > 0:\n",
        "                        month_pct = (count / month_total) * 100\n",
        "                        print(f\"  {calendar.month_name[month]}: {count} occurrences ({month_pct:.1f}%)\")\n",
        "\n",
        "    def analyze_seasonal_precipitation(self):\n",
        "        \"\"\"Analyze seasonal precipitation with table sizing\"\"\"\n",
        "        year = self.year_input.value\n",
        "        column = self.column_selector.value\n",
        "        location = self.location_selector.value if self.location_selector.value != 'ALL' else None\n",
        "\n",
        "        # Filter data for the year\n",
        "        year_df = self.df[\n",
        "            ((self.df['Date/Time'].dt.year == year) |\n",
        "            ((self.df['Date/Time'].dt.year == year - 1) & (self.df['Date/Time'].dt.month == 12)))\n",
        "        ].copy()\n",
        "\n",
        "        if location:\n",
        "            year_df = year_df[year_df['Station Name'] == location]\n",
        "\n",
        "        # Convert to numeric\n",
        "        year_df[column] = pd.to_numeric(year_df[column], errors='coerce')\n",
        "\n",
        "        # Add season column\n",
        "        year_df['Season'] = year_df['Date/Time'].dt.month.apply(get_meteorological_season)\n",
        "\n",
        "        # Calculate seasonal totals\n",
        "        seasonal_totals = year_df.groupby('Season')[column].sum()\n",
        "\n",
        "        # This method is already wrapped in with self.output_area: in run_analysis\n",
        "        clear_output()\n",
        "        print(f\"Seasonal Precipitation Analysis\")\n",
        "        print(f\"Year: {year}\")\n",
        "        print(f\"Column: {column}\")\n",
        "        print(f\"Location: {location or 'All locations'}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        season_order = ['Winter', 'Spring', 'Summer', 'Fall']\n",
        "        table_data = []\n",
        "\n",
        "        for season in season_order:\n",
        "            if season in seasonal_totals:\n",
        "                total = seasonal_totals[season]\n",
        "                table_data.append([season, f\"{total:.1f}\"])\n",
        "\n",
        "        # Annual total\n",
        "        annual_total = year_df[year_df['Date/Time'].dt.year == year][column].sum()\n",
        "        table_data.append([\"Annual\", f\"{annual_total:.1f}\"])\n",
        "\n",
        "        print(tabulate(table_data, headers=[\"Season\", \"Total\"], tablefmt=\"grid\"))\n",
        "        print(\"\\nNote: Winter includes December of previous year\")\n",
        "\n",
        "    def list_threshold_occurrences(self):\n",
        "        \"\"\"List all occurrences above threshold with table sizing\"\"\"\n",
        "        threshold = self.value_input.value\n",
        "        column = self.column_selector.value\n",
        "        start_year = self.start_year_input.value\n",
        "        end_year = self.end_year_input.value\n",
        "        location = self.location_selector.value if self.location_selector.value != 'ALL' else None\n",
        "\n",
        "        # Filter data\n",
        "        filtered_df = self.df.copy()\n",
        "        if start_year > 0:\n",
        "            filtered_df = filtered_df[filtered_df['Date/Time'].dt.year >= start_year]\n",
        "        if end_year > 0:\n",
        "            filtered_df = filtered_df[filtered_df['Date/Time'].dt.year <= end_year]\n",
        "        if location:\n",
        "            filtered_df = filtered_df[filtered_df['Station Name'] == location]\n",
        "\n",
        "        # Convert to numeric and filter by threshold\n",
        "        filtered_df[column] = pd.to_numeric(filtered_df[column], errors='coerce')\n",
        "        threshold_df = filtered_df[filtered_df[column] >= threshold].sort_values('Date/Time')\n",
        "\n",
        "        # This method is already wrapped in with self.output_area: in run_analysis\n",
        "        clear_output()\n",
        "        print(f\"Threshold Occurrences Analysis\")\n",
        "        print(f\"Threshold: {column} >= {threshold}\")\n",
        "        print(f\"Period: {start_year}-{end_year}\")\n",
        "        print(f\"Location: {location or 'All locations'}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        if threshold_df.empty:\n",
        "            print(f\"No occurrences found >= {threshold}\")\n",
        "        else:\n",
        "            print(f\"Total occurrences: {len(threshold_df)}\")\n",
        "            print(f\"\\nAll occurrences:\")\n",
        "\n",
        "            table_data = []\n",
        "            display_limit = 50 if self.show_details_toggle.value else 20\n",
        "\n",
        "            for i, (_, row) in enumerate(threshold_df.iterrows()):\n",
        "                if i >= display_limit:\n",
        "                    break\n",
        "                date = row['Date/Time'].strftime('%Y-%m-%d')\n",
        "                value = row[column]\n",
        "                if location:\n",
        "                    table_data.append([date, f\"{value:.1f}\"])\n",
        "                else:\n",
        "                    table_data.append([date, f\"{value:.1f}\", row['Station Name']])\n",
        "\n",
        "            headers = [\"Date\", \"Value\"] if location else [\"Date\", \"Value\", \"Station\"]\n",
        "            print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
        "\n",
        "            if len(threshold_df) > display_limit:\n",
        "                remaining = len(threshold_df) - display_limit\n",
        "                print(f\"\\n... and {remaining} more occurrences\")\n",
        "                if not self.show_details_toggle.value:\n",
        "                    print(\"(Enable 'Show details' to see up to 50 results)\")\n",
        "\n",
        "    def analyze_winter_snowfall(self):\n",
        "        \"\"\"Analyze top winter snowfall days with table sizing\"\"\"\n",
        "        winter_start_year = self.year_input.value\n",
        "        winter_end_year = winter_start_year + 1\n",
        "        snow_column = \"Total Snow (cm)\"\n",
        "        location = self.location_selector.value if self.location_selector.value != 'ALL' else None\n",
        "\n",
        "        # Filter for winter period (Nov 1 to Apr 30)\n",
        "        winter_mask = (\n",
        "            ((self.df['Date/Time'].dt.year == winter_start_year) &\n",
        "            (self.df['Date/Time'].dt.month >= 11)) |\n",
        "            ((self.df['Date/Time'].dt.year == winter_end_year) &\n",
        "            (self.df['Date/Time'].dt.month <= 4))\n",
        "        )\n",
        "\n",
        "        if location:\n",
        "            winter_mask &= (self.df['Station Name'] == location)\n",
        "\n",
        "        winter_df = self.df[winter_mask].copy()\n",
        "        winter_df[snow_column] = pd.to_numeric(winter_df[snow_column], errors='coerce')\n",
        "        winter_df = winter_df.dropna(subset=[snow_column])\n",
        "\n",
        "        # Get top 5 snowfall days\n",
        "        top_5_snow = winter_df.sort_values(by=snow_column, ascending=False).head(5)\n",
        "\n",
        "        # This method is already wrapped in with self.output_area: in run_analysis\n",
        "        clear_output()\n",
        "        print(f\"Winter Snowfall Analysis\")\n",
        "        print(f\"Winter: {winter_start_year}-{winter_end_year}\")\n",
        "        print(f\"Location: {location or 'All locations'}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        if top_5_snow.empty:\n",
        "            print(f\"No snow data found for winter {winter_start_year}-{winter_end_year}\")\n",
        "        else:\n",
        "            print(f\"Top 5 Snowfall Days:\")\n",
        "\n",
        "            table_data = []\n",
        "            for i, (_, row) in enumerate(top_5_snow.iterrows(), 1):\n",
        "                date = row['Date/Time'].strftime('%Y-%m-%d')\n",
        "                snow = row[snow_column]\n",
        "                if location:\n",
        "                    table_data.append([i, date, f\"{snow:.1f}\"])\n",
        "                else:\n",
        "                    table_data.append([i, date, f\"{snow:.1f}\", row['Station Name']])\n",
        "\n",
        "            headers = [\"Rank\", \"Date\", \"Snow (cm)\"] if location else [\"Rank\", \"Date\", \"Snow (cm)\", \"Station\"]\n",
        "            print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
        "\n",
        "            # Statistics\n",
        "            total_snow = winter_df[snow_column].sum()\n",
        "            days_with_snow = len(winter_df[winter_df[snow_column] > 0])\n",
        "            avg_snow_day = winter_df[winter_df[snow_column] > 0][snow_column].mean()\n",
        "\n",
        "            print(f\"\\nWinter Statistics:\")\n",
        "            stats_data = [\n",
        "                [\"Total snowfall\", f\"{total_snow:.1f} cm\"],\n",
        "                [\"Days with snow\", f\"{days_with_snow}\"],\n",
        "            ]\n",
        "            if days_with_snow > 0:\n",
        "                stats_data.append([\"Average per snow day\", f\"{avg_snow_day:.1f} cm\"])\n",
        "            else:\n",
        "                stats_data.append([\"Average per snow day\", \"N/A\"])\n",
        "\n",
        "\n",
        "            print(tabulate(stats_data, headers=[\"Statistic\", \"Value\"], tablefmt=\"grid\"))\n",
        "\n",
        "    def plot_monthly_precipitation(self):\n",
        "        \"\"\"Plot monthly precipitation.\"\"\"\n",
        "        start_year = self.start_year_input.value\n",
        "        end_year = self.end_year_input.value\n",
        "        month = self.month_selector.value\n",
        "        precip_type = self.precip_type_selector.value\n",
        "        location = self.location_selector.value if self.location_selector.value != 'ALL' else None\n",
        "\n",
        "        # Determine which columns to use based on precip_type\n",
        "        precip_cols = []\n",
        "        if precip_type == 'rain':\n",
        "            precip_cols = [col for col in self.df.columns if 'Rain' in col]\n",
        "        elif precip_type == 'snow':\n",
        "            precip_cols = [col for col in self.df.columns if 'Snow' in col]\n",
        "        elif precip_type == 'precip':\n",
        "            precip_cols = [col for col in self.df.columns if 'Precip' in col]\n",
        "        elif precip_type == 'rain_snow':\n",
        "            precip_cols = [col for col in self.df.columns if 'Rain' in col or 'Snow' in col]\n",
        "\n",
        "        if not precip_cols:\n",
        "            with self.output_area:\n",
        "                clear_output()\n",
        "                print(f\"No relevant precipitation columns found for type: {precip_type}\")\n",
        "            return\n",
        "\n",
        "        # Filter data\n",
        "        filtered_df = self.df.copy()\n",
        "        if start_year > 0:\n",
        "            filtered_df = filtered_df[filtered_df['Date/Time'].dt.year >= start_year]\n",
        "        if end_year > 0:\n",
        "            filtered_df = filtered_df[filtered_df['Date/Time'].dt.year <= end_year]\n",
        "        if month:\n",
        "            filtered_df = filtered_df[filtered_df['Date/Time'].dt.month == month]\n",
        "        if location:\n",
        "            filtered_df = filtered_df[filtered_df['Station Name'] == location]\n",
        "\n",
        "        if filtered_df.empty:\n",
        "            with self.output_area:\n",
        "                clear_output()\n",
        "                print(\"No data found for the selected criteria.\")\n",
        "            return\n",
        "\n",
        "        # Calculate daily total for selected precipitation types\n",
        "        filtered_df['Daily Total Precip'] = filtered_df[precip_cols].sum(axis=1, numeric_only=True)\n",
        "\n",
        "        # Group by year and month and sum the daily totals\n",
        "        monthly_precip = filtered_df.groupby(filtered_df['Date/Time'].dt.to_period('M'))['Daily Total Precip'].sum()\n",
        "        monthly_precip.index = monthly_precip.index.to_timestamp() # Convert PeriodIndex to DatetimeIndex for plotting\n",
        "\n",
        "        with self.output_area:\n",
        "            clear_output()\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            monthly_precip.plot(kind='bar' if len(monthly_precip) <= 24 else 'line') # Use bar for <= 2 years, line otherwise\n",
        "            plt.title(f\"Monthly {precip_type.capitalize()} Precipitation ({calendar.month_name[month] if month else 'All Months'})\")\n",
        "            plt.xlabel(\"Month\")\n",
        "            plt.ylabel(f\"Total Precipitation (mm)\")\n",
        "            plt.xticks(rotation=45, ha='right')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "    def clear_output(self, button):\n",
        "        with self.output_area:\n",
        "            clear_output()\n",
        "        # Reset analysis results and navigation state\n",
        "        self.analysis_results = [] # Reset to empty list\n",
        "        self.current_result_index = 0\n",
        "        self.update_navigation_buttons()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        # Header with theme-adaptive styling\n",
        "        header = widgets.HTML(\n",
        "            \"<div style='text-align: left; padding: 15px; margin-bottom: 10px;'>\"\n",
        "            \"<h2>🌦️ Interactive Weather Data Analyzer</h2>\"\n",
        "            \"<p>Advanced climate analysis with interactive widgets</p>\"\n",
        "            \"</div>\"\n",
        "        )\n",
        "\n",
        "        # Selection panel with options included\n",
        "        selection_panel = widgets.VBox([\n",
        "            widgets.HTML(\"<h3>📍 Data Selection & Update</h3>\"), # Updated title\n",
        "            widgets.HBox([self.province_selector, self.location_selector]),\n",
        "            widgets.HBox([self.show_details_toggle, self.auto_refresh_toggle]),\n",
        "            widgets.HBox([self.load_button, self.progress_bar]),\n",
        "            widgets.VBox([ # New VBox for update options\n",
        "                widgets.HTML(\"<h4>Update Options:</h4>\"),\n",
        "                self.update_type_selector,\n",
        "                self.run_update_button\n",
        "            ], layout=widgets.Layout(border='1px dashed var(--jp-border-color2, #ccc)', padding='10px', margin='10px 0px')) # Added dashed border\n",
        "\n",
        "\n",
        "        ], layout=widgets.Layout(\n",
        "            border='1px solid var(--jp-border-color1, #ddd)',\n",
        "            padding='10px',\n",
        "            margin='5px'\n",
        "        ))\n",
        "\n",
        "        # Analysis panel with year range checkbox\n",
        "        analysis_panel = widgets.VBox([\n",
        "            widgets.HTML(\"<h3>Analysis Configuration</h3>\"),\n",
        "            self.analysis_selector,\n",
        "            self.column_selector,\n",
        "            widgets.HBox([self.value_input, self.year_input, self.month_selector]),\n",
        "            widgets.HBox([self.start_year_input, self.end_year_input, self.use_year_range_toggle]),  # Added checkbox here\n",
        "            widgets.HBox([self.max_min_selector, self.precip_type_selector]),\n",
        "            widgets.HBox([self.analyze_button, self.clear_button]),\n",
        "        ], layout=widgets.Layout(border='1px solid var(--jp-border-color1, #ddd)', padding='10px', margin='5px', width='auto'))\n",
        "\n",
        "        # Combine all panels vertically\n",
        "        self.widget = widgets.VBox([\n",
        "            header,\n",
        "            widgets.HBox([selection_panel, analysis_panel]),\n",
        "            self.results_plots_panel # Use the results_plots_panel defined in setup_widgets\n",
        "        ])\n",
        "\n",
        "    def display(self):\n",
        "        display(self.widget)\n",
        "        # Auto-initialize province and analysis type\n",
        "        self.on_province_change({'new': self.province_selector.value})\n",
        "        # Trigger analysis change to set up default state\n",
        "        self.on_analysis_change({'new': self.analysis_selector.value})"
      ],
      "metadata": {
        "id": "9dx1M-wdIcHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Widget Display"
      ],
      "metadata": {
        "id": "__fQSMGOfnfV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b3b1a1e"
      },
      "source": [
        "# Initialize and display\n",
        "analyzer = InteractiveWeatherAnalyzer('/content/drive/MyDrive/Climate Data/Daily Data')\n",
        "analyzer.display()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}